{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df4f56c1-f16c-4903-be1b-2cf50e73386a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Access confirmed to: \\\\data2\\CommercialData\\Factiva_Repository\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing JSON files in \\\\data2\\CommercialData\\Factiva_Repository: 0it [00:00, ?it/s]\n",
      "Processing JSON files in \\\\data2\\CommercialData\\Factiva_Repository\\2020: 100%|█████████| 25/25 [02:58<00:00,  7.16s/it]\n",
      "Processing JSON files in \\\\data2\\CommercialData\\Factiva_Repository\\2021: 100%|█████████| 25/25 [03:18<00:00,  7.93s/it]\n",
      "Processing JSON files in \\\\data2\\CommercialData\\Factiva_Repository\\2022: 100%|█████████| 25/25 [04:01<00:00,  9.65s/it]\n",
      "Processing JSON files in \\\\data2\\CommercialData\\Factiva_Repository\\2023: 100%|█████████| 25/25 [04:32<00:00, 10.91s/it]\n",
      "Processing JSON files in \\\\data2\\CommercialData\\Factiva_Repository\\2024: 100%|█████████| 33/33 [04:20<00:00,  7.89s/it]\n",
      "Processing JSON files in \\\\data2\\CommercialData\\Factiva_Repository\\2005: 100%|█████████| 25/25 [00:00<00:00, 34.70it/s]\n",
      "Processing JSON files in \\\\data2\\CommercialData\\Factiva_Repository\\2006: 100%|█████████| 25/25 [00:50<00:00,  2.01s/it]\n",
      "Processing JSON files in \\\\data2\\CommercialData\\Factiva_Repository\\2007: 100%|█████████| 25/25 [00:49<00:00,  2.00s/it]\n",
      "Processing JSON files in \\\\data2\\CommercialData\\Factiva_Repository\\2008: 100%|█████████| 25/25 [00:57<00:00,  2.31s/it]\n",
      "Processing JSON files in \\\\data2\\CommercialData\\Factiva_Repository\\2009: 100%|█████████| 25/25 [01:16<00:00,  3.04s/it]\n",
      "Processing JSON files in \\\\data2\\CommercialData\\Factiva_Repository\\2010: 100%|█████████| 25/25 [01:41<00:00,  4.06s/it]\n",
      "Processing JSON files in \\\\data2\\CommercialData\\Factiva_Repository\\2011: 100%|█████████| 25/25 [01:44<00:00,  4.16s/it]\n",
      "Processing JSON files in \\\\data2\\CommercialData\\Factiva_Repository\\2012: 100%|█████████| 25/25 [01:39<00:00,  3.96s/it]\n",
      "Processing JSON files in \\\\data2\\CommercialData\\Factiva_Repository\\2013: 100%|█████████| 25/25 [02:00<00:00,  4.84s/it]\n",
      "Processing JSON files in \\\\data2\\CommercialData\\Factiva_Repository\\2014: 100%|█████████| 25/25 [02:04<00:00,  4.97s/it]\n",
      "Processing JSON files in \\\\data2\\CommercialData\\Factiva_Repository\\2015: 100%|█████████| 25/25 [02:14<00:00,  5.38s/it]\n",
      "Processing JSON files in \\\\data2\\CommercialData\\Factiva_Repository\\2016: 100%|█████████| 25/25 [02:35<00:00,  6.23s/it]\n",
      "Processing JSON files in \\\\data2\\CommercialData\\Factiva_Repository\\2017: 100%|█████████| 25/25 [02:36<00:00,  6.24s/it]\n",
      "Processing JSON files in \\\\data2\\CommercialData\\Factiva_Repository\\2018: 100%|█████████| 25/25 [03:01<00:00,  7.25s/it]\n",
      "Processing JSON files in \\\\data2\\CommercialData\\Factiva_Repository\\2019: 100%|█████████| 25/25 [03:11<00:00,  7.65s/it]\n",
      "Processing JSON files in \\\\data2\\CommercialData\\Factiva_Repository\\2025: 100%|███████████| 8/8 [01:35<00:00, 11.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns:  ['id', 'title', 'snippet', 'body', 'source_name', 'publication_date', 'language', 'word_count', 'region', 'industry_codes', 'subject_codes']\n",
      "Number of articles:  19795095\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "\n",
    "# Base path to the Factiva repository on the shared drive\n",
    "base_folder = r\"\\\\data2\\CommercialData\\Factiva_Repository\"\n",
    "\n",
    "# Step 1: Check if the base folder is accessible\n",
    "if not os.path.exists(base_folder):\n",
    "    print(f\"Folder not accessible: {base_folder}\")\n",
    "    exit(1)  # Exit the script if the folder does not exist or access is denied\n",
    "else:\n",
    "    print(f\"Access confirmed to: {base_folder}\")\n",
    "\n",
    "# Step 2: Initialize a list to store all extracted article records\n",
    "all_records = []\n",
    "\n",
    "# Step 3: Traverse all subdirectories and process each JSON file\n",
    "for root, dirs, files in os.walk(base_folder):\n",
    "    for filename in tqdm(files, desc=f\"Processing JSON files in {root}\"):\n",
    "        if filename.endswith(\".json\"):  # Only process .json files\n",
    "            file_path = os.path.join(root, filename)\n",
    "            try:\n",
    "                # Open and load the JSON file\n",
    "                with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                    data = json.load(f)\n",
    "\n",
    "                    # Ensure the data is a list (even if only one article is present)\n",
    "                    if isinstance(data, dict):\n",
    "                        data = [data]\n",
    "\n",
    "                    # Extract relevant fields from each article\n",
    "                    for item in data:\n",
    "                        record = {\n",
    "                            \"id\": item.get(\"an\"),\n",
    "                            \"title\": item.get(\"title\"),\n",
    "                            \"snippet\": item.get(\"snippet\"),\n",
    "                            \"body\": item.get(\"body\"),\n",
    "                            \"source_name\": item.get(\"source_name\"),\n",
    "                            \"publication_date\": item.get(\"publication_date\"),\n",
    "                            \"language\": item.get(\"language_code\"),\n",
    "                            \"word_count\": item.get(\"word_count\"),\n",
    "                            \"region\": item.get(\"region_of_origin\"),\n",
    "                            \"industry_codes\": item.get(\"industry_codes\"),\n",
    "                            \"subject_codes\": item.get(\"subject_codes\"),\n",
    "                        }\n",
    "                        all_records.append(record)\n",
    "            except json.JSONDecodeError as e:\n",
    "                print(f\"JSON decode error in file {file_path}: {e}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Unexpected error in file {file_path}: {e}\")\n",
    "\n",
    "# Step 4: Convert the list of records into a pandas DataFrame\n",
    "df = pd.DataFrame(all_records)\n",
    "\n",
    "# Print a summary: column names and number of articles\n",
    "print(\"Columns: \", df.columns.tolist())\n",
    "print(\"Number of articles: \", len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e233192-3e80-4b90-9e55-c76face4d8a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19795095, 11)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9654eef5-0c9c-4b06-8ccb-023534ca2e68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "language\n",
      "en       56.9 %\n",
      "es      23.66 %\n",
      "fr       9.47 %\n",
      "zhcn     8.79 %\n",
      "ar       1.18 %\n",
      "Name: proportion, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Display the distribution of articles by language (as percentages)\n",
    "language_distribution = df['language'].value_counts(normalize=True)\n",
    "\n",
    "# Format as percentage and print\n",
    "print((language_distribution * 100).round(2).astype(str) + ' %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c9ad539a-ba62-45a8-b0f3-a75173d19d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_en = df[df['language'] == 'en']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "48fc9873-6b94-447c-89f6-bc46f8837dfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11263164, 11)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_en.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "772ad08d-862b-4628-8fc9-639d45c5fcf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_es = df[df['language'] == 'es']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2534f3ab-0c74-48f2-aeaf-d91c4d32ad71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4683714, 11)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_es.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "09511fb2-269b-42ce-8a29-2970ed5fd401",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fr = df[df['language'] == 'fr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5157cbbb-f3b4-4b5a-8a26-3d1cb1d6d338",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1874542, 11)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fr.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee164f29-4b3c-426d-8ed6-a4782d83d6cd",
   "metadata": {},
   "source": [
    "### Construct local and global Trade Policy Uncertainty (TPU) indices using text data from local and global news sources, drawing on the approaches of Caldara et al. (2018) and Bloom et al. (2016)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "edb9b1ad-c9a1-4e07-8d8d-fb2f29d83058",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: swifter in e:\\profiles\\fayivodji\\appdata\\roaming\\python\\python312\\site-packages (1.4.0)\n",
      "Requirement already satisfied: pandas>=1.0.0 in d:\\apps\\python312\\lib\\site-packages (from swifter) (2.2.2)\n",
      "Requirement already satisfied: psutil>=5.6.6 in d:\\apps\\python312\\lib\\site-packages (from swifter) (6.0.0)\n",
      "Requirement already satisfied: dask>=2.10.0 in e:\\profiles\\fayivodji\\appdata\\roaming\\python\\python312\\site-packages (from dask[dataframe]>=2.10.0->swifter) (2025.5.1)\n",
      "Requirement already satisfied: tqdm>=4.33.0 in e:\\profiles\\fayivodji\\appdata\\roaming\\python\\python312\\site-packages (from swifter) (4.67.1)\n",
      "Requirement already satisfied: click>=8.1 in d:\\apps\\python312\\lib\\site-packages (from dask>=2.10.0->dask[dataframe]>=2.10.0->swifter) (8.1.7)\n",
      "Requirement already satisfied: cloudpickle>=3.0.0 in d:\\apps\\python312\\lib\\site-packages (from dask>=2.10.0->dask[dataframe]>=2.10.0->swifter) (3.0.0)\n",
      "Requirement already satisfied: fsspec>=2021.09.0 in e:\\profiles\\fayivodji\\appdata\\roaming\\python\\python312\\site-packages (from dask>=2.10.0->dask[dataframe]>=2.10.0->swifter) (2024.12.0)\n",
      "Requirement already satisfied: packaging>=20.0 in d:\\apps\\python312\\lib\\site-packages (from dask>=2.10.0->dask[dataframe]>=2.10.0->swifter) (24.1)\n",
      "Requirement already satisfied: partd>=1.4.0 in e:\\profiles\\fayivodji\\appdata\\roaming\\python\\python312\\site-packages (from dask>=2.10.0->dask[dataframe]>=2.10.0->swifter) (1.4.2)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in d:\\apps\\python312\\lib\\site-packages (from dask>=2.10.0->dask[dataframe]>=2.10.0->swifter) (6.0.1)\n",
      "Requirement already satisfied: toolz>=0.10.0 in e:\\profiles\\fayivodji\\appdata\\roaming\\python\\python312\\site-packages (from dask>=2.10.0->dask[dataframe]>=2.10.0->swifter) (1.0.0)\n",
      "Requirement already satisfied: pyarrow>=14.0.1 in e:\\profiles\\fayivodji\\appdata\\roaming\\python\\python312\\site-packages (from dask[dataframe]>=2.10.0->swifter) (20.0.0)\n",
      "Requirement already satisfied: numpy>=1.26.0 in e:\\profiles\\fayivodji\\appdata\\roaming\\python\\python312\\site-packages (from pandas>=1.0.0->swifter) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in d:\\apps\\python312\\lib\\site-packages (from pandas>=1.0.0->swifter) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\apps\\python312\\lib\\site-packages (from pandas>=1.0.0->swifter) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in d:\\apps\\python312\\lib\\site-packages (from pandas>=1.0.0->swifter) (2024.1)\n",
      "Requirement already satisfied: colorama in d:\\apps\\python312\\lib\\site-packages (from tqdm>=4.33.0->swifter) (0.4.6)\n",
      "Requirement already satisfied: locket in e:\\profiles\\fayivodji\\appdata\\roaming\\python\\python312\\site-packages (from partd>=1.4.0->dask>=2.10.0->dask[dataframe]>=2.10.0->swifter) (1.0.0)\n",
      "Requirement already satisfied: six>=1.5 in d:\\apps\\python312\\lib\\site-packages (from python-dateutil>=2.8.2->pandas>=1.0.0->swifter) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install swifter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "abb8dc12-1086-4102-87e0-dc7c6673150b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import swifter\n",
    "import time\n",
    "\n",
    "# Enable progress bars for swifter and tqdm\n",
    "tqdm.pandas()\n",
    "swifter.config.progress_bar = True\n",
    "\n",
    "class TPUDetector:\n",
    "    def __init__(self):\n",
    "        # Compile regex for trade-related terms\n",
    "        self.trade_terms = re.compile(\n",
    "            r\"(USMCA|NAFTA|CUSMA|WTO|World Trade Organization|GATT|General Agreement on Tariffs and Trade|\"\n",
    "            r\"Doha Round|Uruguay Round|trade polic(?:y|ies)|trade agreement(?:s)?|free trade(?: agreement(?:s)?)?|\"\n",
    "            r\"FTA(?:s)?|preferential trade|bilateral trade|multilateral trade|trade negotiation(?:s)?|\"\n",
    "            r\"trade act(?:s)?|trade treat(?:y|ies)|trade rule(?:s)?|trade friction(?:s)?|market access|\"\n",
    "            r\"tariff(?:s)?|retaliatory tariff(?:s)?|retaliation|import tariff(?:s)?|export tariff(?:s)?|\"\n",
    "            r\"tariff dut(?:y|ies)|custom(?:s)? dut(?:y|ies)|duty on import(?:s)?|import dut(?:y|ies)|\"\n",
    "            r\"import barrier(?:s)?|import restriction(?:s)?|import liberalization|export restriction(?:s)?|\"\n",
    "            r\"export subsid(?:y|ies)|\\b(import|imports|imported|importing)\\b|\\b(export|exports|exported|exporting)\\b|\"\n",
    "            r\"border(?:s)?|trade barrier(?:s)?|non-tariff barrier(?:s)?|trade remed(?:y|ies)|\"\n",
    "            r\"countervailing dut(?:y|ies)|trade dispute(?:s)?|trade panel(?:s)?|WTO ruling(?:s)?|\"\n",
    "            r\"trade tribunal(?:s)?|trade retaliation(?:s)?|trade sanction(?:s)?|trade enforcement|protectionism|\"\n",
    "            r\"unilateralism|trade liberalization|international trade|import (ban|tax|subsid)(?:es)?|\"\n",
    "            r\"export (ban|tax|subsid)(?:es)?|border (ban|tax|subsid)(?:es)?|trade facilitation|escalating trade|\"\n",
    "            r\"trade partnership(?:s)?|trade adjustment assistance|customs tariff(?:s)?|tariff preference(?:s)?|\"\n",
    "            r\"trade restriction(?:s)?|trade embargo(?:es)?|import surcharge(?:s)?|sectoral tariff(?:s)?|\"\n",
    "            r\"preferential tariff(?:s)?|reciprocal tariff(?:s)?|customs valuation rule(?:s)?|\"\n",
    "            r\"import licensing requirement(?:s)?|rules of origin restriction(?:s)?|export control(?:s)?|\"\n",
    "            r\"trade tax(?:es)?|import protection|protectionist barrier(?:s)?|plurilateral(?:s)?|\"\n",
    "            r\"subsidies and countervailing measures|trade-restrictive|trade-facilitating|strategic tariff(?:s)?|\"\n",
    "            r\"GATT ruling(?:s)?|WTO panel(?:s)?|GATT panel(?:s)?|WTO case(?:s)?|trade war(?:s)?|\"\n",
    "            r\"customs union(?:s)?|anti-dumping)\",\n",
    "            flags=re.IGNORECASE\n",
    "        )\n",
    "\n",
    "        # Compile regex for uncertainty-related terms\n",
    "        self.uncertainty_terms = re.compile(\n",
    "            r\"(uncertain(?:ty|ties)?|unpredictabl(?:e|ility)?|volatil(?:e|ity)|downside risk|upside risk|unexpected|\"\n",
    "            r\"unknown|crisis|crises|war|unclear|tension(?:s)?|danger(?:s)?|fear(?:s)?|concern(?:s|ed| about)?|\"\n",
    "            r\"caution|worr(?:y|ies)?|anxious|anxiety|unease|unstabl(?:e|ity)|threat(?:s)?|threaten(?:s|ed|ing)?|\"\n",
    "            r\"ambiguous|ambiguity|imprecise|vague|unresolved|unanticipated|unforeseen|hesitant|hesitation|\"\n",
    "            r\"doubt(?:ful|s)?|skeptic(?:al|ism)?|murky|precarious|tentative|fluid|chang(?:eable|ing)|shifting|\"\n",
    "            r\"wavering|turmoil|turbulent|turbulence|fragil(?:e|ity)|fluctuation(?:s)?|slowdown|downturn|\"\n",
    "            r\"depression|recession(?:ary)?|pessimism|pessimistic|stagflation|erosion|deterioration|meltdown|\"\n",
    "            r\"bubble burst|stress(?:ed)?|distress|vulnerab(?:le|ility|ilities)?|apprehensive|possibilit(?:y|ies)?|\"\n",
    "            r\"likelihood|probabilit(?:y|ies)?|prospect(?:s)?|potential|speculat(?:ion|ive)|rumor(?:s)?|\"\n",
    "            r\"rumours?|bleak|gloom|nervousness|cautious|wary|unconfirmed|pressure(?:s)?|confusion|\"\n",
    "            r\"challenge\\w*|dispute(?:s)?|issue(?:s)?|dubious)\",\n",
    "            flags=re.IGNORECASE\n",
    "        )\n",
    "\n",
    "        # Combined pattern: trade and uncertainty terms within 10 words of each other\n",
    "        self.tpu_pattern = re.compile(\n",
    "            rf\"({self.trade_terms.pattern}(?:\\W+\\w+){{1,10}}{self.uncertainty_terms.pattern})|\"\n",
    "            rf\"({self.uncertainty_terms.pattern}(?:\\W+\\w+){{1,10}}{self.trade_terms.pattern})\",\n",
    "            flags=re.IGNORECASE\n",
    "        )\n",
    "\n",
    "    def normalize_text_preserving_acronyms(self, text: str) -> str:\n",
    "        \"\"\"Clean text by removing punctuation and lowering case, while preserving acronyms (e.g., IMF, WTO).\"\"\"\n",
    "        if not isinstance(text, str):\n",
    "            return \"\"\n",
    "        # Identify acronyms (e.g., IMF, WTO) and temporarily replace them\n",
    "        acronyms = re.findall(r'\\b[A-Z]{2,}\\b', text)\n",
    "        for i, ac in enumerate(acronyms):\n",
    "            text = text.replace(ac, f\"__ACRO_{i}__\")\n",
    "        text = re.sub(r\"[^\\w\\s]\", \" \", text).lower()\n",
    "        for i, ac in enumerate(acronyms):\n",
    "            text = text.replace(f\"__acro_{i}__\", ac)\n",
    "        return text\n",
    "\n",
    "    def detect_tpu(self, text: str) -> bool:\n",
    "        \"\"\"Return True if both trade and uncertainty terms co-occur within a 10-word window.\"\"\"\n",
    "        return bool(self.tpu_pattern.search(str(text)))\n",
    "\n",
    "    def apply_to_dataframe(self, df: pd.DataFrame, text_column: str = \"body\") -> pd.DataFrame:\n",
    "        \"\"\"Clean the text column, apply TPU detection, and return updated DataFrame.\"\"\"\n",
    "        df = df.copy()\n",
    "        df[text_column] = df[text_column].fillna('')\n",
    "        df[\"body_clean\"] = df[text_column].apply(self.normalize_text_preserving_acronyms)\n",
    "\n",
    "        print(\"Running TPU detection with swifter...\")\n",
    "        start = time.time()\n",
    "        df[\"tpu_flag\"] = df[\"body_clean\"].swifter.apply(self.detect_tpu).astype(int)\n",
    "        print(f\"Completed in {round(time.time() - start, 2)} seconds.\")\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa0496c-c4be-4c83-8dbf-4cfa2f49c6eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the TPU detector\n",
    "tpu_detector = TPUDetector()\n",
    "\n",
    "# Apply it to your filtered trade-related articles\n",
    "df_en_with_tpu = tpu_detector.apply_to_dataframe(df_en, text_column=\"body\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4022a8e4-250d-4d41-8655-92b8f5846c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert timestamp (in milliseconds) to a readable date\n",
    "df_en_with_tpu['pub_date_readable'] = pd.to_datetime(df_en_with_tpu['publication_date'], unit='ms')\n",
    "\n",
    "# Extract year and month from the publication date\n",
    "df_en_with_tpu['pub_year'] = df_en_with_tpu['pub_date_readable'].dt.year\n",
    "df_en_with_tpu['pub_month'] = df_en_with_tpu['pub_date_readable'].dt.month\n",
    "\n",
    "# Sort articles by publication date\n",
    "df_en_with_tpu.sort_values(by='pub_date_readable', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc05b6cd-df84-41ca-b2be-03935b7c5d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Add a monthly period column based on publication date\n",
    "df_en_with_tpu['pub_period'] = df_en_with_tpu['pub_date_readable'].dt.to_period('M')\n",
    "\n",
    "# Step 2: Define a function to compute the TPU index by time period (or any group)\n",
    "def compute_tpu_index_grouped(df, group_cols=['pub_date_readable'], text_col='body_clean', flag_col='tpu_flag', freq='M'):\n",
    "    df = df.copy()\n",
    "\n",
    "    # Convert to datetime if grouping by date column\n",
    "    if 'pub_date_readable' in group_cols:\n",
    "        df['pub_date_readable'] = pd.to_datetime(df['pub_date_readable'])\n",
    "        if freq:\n",
    "            # Convert to period, then back to timestamp for grouping\n",
    "            df['period'] = df['pub_date_readable'].dt.to_period(freq).dt.to_timestamp()\n",
    "            group_cols = ['period'] + [col for col in group_cols if col != 'pub_date_readable']\n",
    "\n",
    "    # Group by selected columns and compute total articles and TPU-flagged articles\n",
    "    grouped = df.groupby(group_cols).agg(\n",
    "        NUMBER_ARTICLES=(text_col, 'count'),\n",
    "        TPUD_ARTICLES=(flag_col, 'sum')\n",
    "    ).reset_index()\n",
    "\n",
    "    # Compute TPU index as percentage\n",
    "    grouped['TPUD_index'] = (grouped['TPUD_ARTICLES'] / grouped['NUMBER_ARTICLES'] * 100).round(2)\n",
    "\n",
    "    # Ensure article counts are integer type\n",
    "    grouped['NUMBER_ARTICLES'] = grouped['NUMBER_ARTICLES'].astype(int)\n",
    "    grouped['TPUD_ARTICLES'] = grouped['TPUD_ARTICLES'].astype(int)\n",
    "\n",
    "    return grouped\n",
    "\n",
    "# Step 3: Compute the monthly TPU index using df_en_with_tpu\n",
    "monthly_tpu_all = compute_tpu_index_grouped(\n",
    "    df=df_en_with_tpu,\n",
    "    group_cols=['pub_date_readable'],\n",
    "    text_col='body_clean',\n",
    "    flag_col='tpu_flag',\n",
    "    freq='M'  # monthly frequency\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0840e11-62cd-4bdc-af7a-b507a1e9fe4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure the period column is in datetime format for plotting\n",
    "monthly_tpu_all['pub_month_period'] = pd.to_datetime(monthly_tpu_all['pub_month_period'])\n",
    "\n",
    "# Scale the TPU index (multiply by 100) for better percentage-based display\n",
    "monthly_tpu_all['TPUD_index_scaled'] = monthly_tpu_all['TPUD_index'] * 100\n",
    "\n",
    "# Create the figure and axis\n",
    "fig, ax = plt.subplots(figsize=(14, 6))\n",
    "\n",
    "# Plot the TPU index over time using a clean line style\n",
    "ax.plot(\n",
    "    monthly_tpu_all['pub_month_period'],\n",
    "    monthly_tpu_all['TPUD_index_scaled'],\n",
    "    marker='o',\n",
    "    linestyle='-',\n",
    "    linewidth=2,\n",
    "    color='navy',\n",
    "    label='TPU Index'\n",
    ")\n",
    "\n",
    "# Add title and axis labels\n",
    "ax.set_title('Factiva - Global Trade Policy Uncertainty Index', fontsize=16, fontweight='bold')\n",
    "ax.set_xlabel('Month', fontsize=13)\n",
    "ax.set_ylabel('GTPU Index', fontsize=13)\n",
    "\n",
    "# Remove gridlines for a cleaner look\n",
    "ax.grid(False)\n",
    "\n",
    "# Format x-axis to show one tick every 12 months\n",
    "ax.xaxis.set_major_locator(mdates.MonthLocator(interval=12))\n",
    "ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m'))\n",
    "\n",
    "# Rotate x-axis labels for better readability\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "\n",
    "# Improve layout and spacing\n",
    "plt.tight_layout()\n",
    "\n",
    "# Add legend (useful even for a single line for formal completeness)\n",
    "ax.legend(loc='upper left', fontsize=12)\n",
    "\n",
    "# Remove top and right borders for a cleaner visual\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a2ff00b-248b-4bf6-880a-06d7c50195fc",
   "metadata": {},
   "source": [
    "### Filter English-language articles related to trade using keyword matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1484c483-3421-43e2-9480-7e8b154d81ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TradeArticleFilter:\n",
    "    def __init__(self):\n",
    "        # Define the list of trade-related keywords (with regex for plural/singular variants)\n",
    "        self.keywords = [\n",
    "\n",
    "            # Basic trade terms\n",
    "            r\"import(?:s|ing)?\", r\"export(?:s|ing)?\", r\"export(?:ing)? market(?:s)?\", r\"export competitiven(?:ess)?\",\n",
    "            r\"importing\", r\"exporting\", r\"trading\", r\"trade(?:s|d|ing)?\", r\"commerce\", r\"global trade\", r\"import licence(?:s)?\",\n",
    "            r\"goods trade\", r\"service(?:s)? trade\", r\"services trade\", r\"GTA\",\n",
    "\n",
    "            # Tariffs and duties\n",
    "            r\"tariff(?:s)?\", r\"tariff(?:s)? hike\", r\"tariff(?:s)? increase\", r\"tariff(?:s)? cut\",\n",
    "            r\"tariff(?:s)? exemption\", r\"retaliatory tariff(?:s)?\", r\"tariff quota(?:s)?\", r\"tariff binding\",\n",
    "            r\"ad valorem tariff(?:s)?\", r\"border tax adjustment\", r\"countervailing dut(?:y|ies)?\",\n",
    "            r\"customs dut(?:y|ies)\", r\"custom duties\", r\"import dut(?:y|ies)\", r\"export dut(?:y|ies)\", r\"import tax(?:e|es)?\", \n",
    "            r\"countervailing\", r\"countervailing duty\",\n",
    "\n",
    "            # Trade agreements\n",
    "            r\"free trade agreement(?:s)?\", r\"bilateral trade agreement(?:s)?\", r\"multilateral trade agreement(?:s)?\",\n",
    "            r\"preferential trade agreement(?:s)?\", r\"regional trade agreement(?:s)?\", r\"trade treaty(?:ies)?\",\n",
    "            r\"trade agreement(?:s)?\", r\"FTA(?:s)?\", r\"NAFTA\", r\"CUSMA\", r\"USMCA\", r\"CAFTA\",\n",
    "\n",
    "            # Institutions and mechanisms\n",
    "            r\"WTO(?: dispute| ruling| panel)?\", r\"WTO negotiation(?:s)?\", r\"World Trade Organization\",\n",
    "            r\"wto dispute\", r\"GATT\", r\"Doha round\", r\"Uruguay round\",\n",
    "\n",
    "            # Barriers and restrictions\n",
    "            r\"non-tariff barrier(?:s)?\", r\"non-tariff measure(?:s)?\", r\"nontariff measure(?:s)?\",\n",
    "            r\"technical trade barrier(?:s)?\", r\"import ban(?:s)?\", r\"export ban(?:s)?\",\n",
    "            r\"export barrier(?:s)?\", r\"import barrier(?:s)?\", r\"trade embargo(?:es)?\", r\"quotas?\",\n",
    "            r\"import quota(?:s)?\", r\"export quota(?:s)?\", r\"binding quota(?:s)?\", r\"non-binding quota(?:s)?\",\n",
    "            r\"safeguard measure(?:s)?\", r\"rules of origin\", r\"local content\", r\"local content requirement(?:s)?\",\n",
    "            r\"voluntary export restraint(?:s)?\", r\"voluntary export\", r\"voluntary export restraint arrangements\",\n",
    "            r\"voluntary import expansion\", r\"tariff quota\", r\"trade-related investment measure(?:s)?\",\n",
    "            r\"export credits?\", r\"export control(?:s)?\", r\"customs (?:procedure|reform|clearance)\",\n",
    "            r\"customs enforcement\",\n",
    "\n",
    "            # Trade policy\n",
    "            r\"foreign trade policy\", r\"trade policy\", r\"trade policy uncertainty\", r\"uncertain trade environment\",\n",
    "            r\"protectionist polic(?:y|ies)\", r\"liberalization polic(?:y|ies)?\", r\"trade liberalization\",\n",
    "            r\"policy reversal(?:s)?\", r\"policy backtracking\", r\"trade spillover(?:s)?\",\n",
    "\n",
    "            # Supply chains and logistics\n",
    "            r\"supply chain(?: disruption(?:s)?| shock(?:s)?| bottleneck(?:s)?| resilience| pressure(?:s)?)?\",\n",
    "            r\"supply[- ]chain(?: disruption(?:s)?| shock(?:s)?| bottleneck(?:s)?| resilience| pressure(?:s)?)?\",\n",
    "            r\"global value chain(?:s)?\", r\"GVC(?:s)?\", r\"port congestion\", r\"shipping delay(?:s)?\",\n",
    "            r\"container shortage(?:s)?\", r\"logistics disruption(?:s)?\", r\"reshoring\", r\"nearshoring\",\n",
    "            r\"friend-shoring\", r\"cargo\",\n",
    "\n",
    "            # Geopolitical factors\n",
    "            r\"geopolitical tension(?:s)?\", r\"geopolitical shock(?:s)?\", r\"geopolitical concern(?:s)?\",\n",
    "            r\"geopolitical fragmentation\", r\"geo-economic fragmentation\", r\"geoeconomic fragmentation\",\n",
    "            r\"geoeconomic\", r\"geopolitical\", r\"geopolitics\", r\"economic fragmentation\",\n",
    "            r\"strategic competitiveness\", r\"economic coercion\", r\"trade war(?:s)?\", r\"trade tension(?:s)?\",\n",
    "            r\"trade disruption(?:s)?\", r\"fragmented trade\",\n",
    "\n",
    "            # External sector\n",
    "            r\"external sector\", r\"FX intervention(?:s)?\", r\"foreign exchange intervention(?:s)?\",\n",
    "            r\"foreign exchange market\", r\"foreign exchange polic(?:y|ies)?\",\n",
    "            r\"international reserve(?:s)?\", r\"foreign exchange reserve(?:s)?\", r\"foreign asset(?:s)?\",\n",
    "            r\"real exchange rate\", r\"current account\",\n",
    "\n",
    "            # Other macro indicators\n",
    "            r\"commodity price (?:shock|surge)\", r\"commodity export ban(?:s)?\",\n",
    "            r\"trade balance\", r\"trade deficit\", r\"net-commodity-importing\", r\"FDI measures\",\n",
    "        ]\n",
    "\n",
    "        # Compile regex pattern once for performance\n",
    "        self.pattern = re.compile(r\"(?:{})\".format(\"|\".join(self.keywords)), flags=re.IGNORECASE)\n",
    "\n",
    "    def filter(self, df, text_column=\"snippet\"):\n",
    "        \"\"\"Filter rows in a DataFrame where the text_column contains trade-related content.\"\"\"\n",
    "        df_filtered = df[df[text_column].str.contains(self.pattern, na=False)].copy()\n",
    "        df_filtered.reset_index(drop=True, inplace=True)\n",
    "        return df_filtered\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d381ded2-c34f-4f5d-b486-12f48e63b605",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the filter\n",
    "trade_filter = TradeArticleFilter()\n",
    "\n",
    "# Apply it to English articles DataFrame (df_en)\n",
    "df_trade = trade_filter.filter(df_en, text_column=\"snippet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "af113d3c-daf2-4185-9992-10a656117c15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1775175, 11)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_trade.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9c8a3bf9-fe74-43e4-a08e-b952f5f7b38b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>snippet</th>\n",
       "      <th>body</th>\n",
       "      <th>source_name</th>\n",
       "      <th>publication_date</th>\n",
       "      <th>language</th>\n",
       "      <th>word_count</th>\n",
       "      <th>region</th>\n",
       "      <th>industry_codes</th>\n",
       "      <th>subject_codes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KYRGYZE020200121eg1h00015</td>\n",
       "      <td>Copper leads price hike in non-ferrous base me...</td>\n",
       "      <td>Copper climbed to an eight-month high on Thurs...</td>\n",
       "      <td>“I'm cautiously optimistic on the outlook for ...</td>\n",
       "      <td>Kyrgyzstan Newsline</td>\n",
       "      <td>1579219200000</td>\n",
       "      <td>en</td>\n",
       "      <td>417</td>\n",
       "      <td>ASIA CASIAZ KIRGH USSRZ</td>\n",
       "      <td></td>\n",
       "      <td>,gtrade,e51,ecat,gcat,gdip,gpir,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OMDLOB0020200106eg150000g</td>\n",
       "      <td>Second phase targets policies, capabilities</td>\n",
       "      <td>The Sultanate is making efforts to achieve str...</td>\n",
       "      <td>According to Sami bin Salem al Saheb, Director...</td>\n",
       "      <td>Oman Daily Observer</td>\n",
       "      <td>1578182400000</td>\n",
       "      <td>en</td>\n",
       "      <td>481</td>\n",
       "      <td>ASIA GULFST MEASTZ OMAN WASIAZ</td>\n",
       "      <td></td>\n",
       "      <td>,gvbod,c13,ccat,gcat,gpir,gpol,ncat,nfact,nfcpin,</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          id  \\\n",
       "0  KYRGYZE020200121eg1h00015   \n",
       "1  OMDLOB0020200106eg150000g   \n",
       "\n",
       "                                               title  \\\n",
       "0  Copper leads price hike in non-ferrous base me...   \n",
       "1        Second phase targets policies, capabilities   \n",
       "\n",
       "                                             snippet  \\\n",
       "0  Copper climbed to an eight-month high on Thurs...   \n",
       "1  The Sultanate is making efforts to achieve str...   \n",
       "\n",
       "                                                body          source_name  \\\n",
       "0  “I'm cautiously optimistic on the outlook for ...  Kyrgyzstan Newsline   \n",
       "1  According to Sami bin Salem al Saheb, Director...  Oman Daily Observer   \n",
       "\n",
       "  publication_date language word_count                           region  \\\n",
       "0    1579219200000       en        417         ASIA CASIAZ KIRGH USSRZ    \n",
       "1    1578182400000       en        481  ASIA GULFST MEASTZ OMAN WASIAZ    \n",
       "\n",
       "  industry_codes                                      subject_codes  \n",
       "0                                  ,gtrade,e51,ecat,gcat,gdip,gpir,  \n",
       "1                 ,gvbod,c13,ccat,gcat,gpir,gpol,ncat,nfact,nfcpin,  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_trade.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d9c9817c-0585-4356-9219-5fde6c5472e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>snippet</th>\n",
       "      <th>body</th>\n",
       "      <th>source_name</th>\n",
       "      <th>publication_date</th>\n",
       "      <th>language</th>\n",
       "      <th>word_count</th>\n",
       "      <th>region</th>\n",
       "      <th>industry_codes</th>\n",
       "      <th>subject_codes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1775173</th>\n",
       "      <td>NBFSTA0020250129el1t0000k</td>\n",
       "      <td>Jamaat-e-Islami Emir Hafiz Naeem ur Rehman ann...</td>\n",
       "      <td>Jamaat-e-Islami Emir Hafiz Naeem ur Rehman has...</td>\n",
       "      <td>He hailed the return of millions of Gazans to ...</td>\n",
       "      <td>Frontier Star</td>\n",
       "      <td>1738108800000</td>\n",
       "      <td>en</td>\n",
       "      <td>542</td>\n",
       "      <td>ASIA PAKIS SASIAZ</td>\n",
       "      <td>,i1,i16,ieutil,iutil,</td>\n",
       "      <td>,c314,ccat,cdom,gcat,gcivds,gcns,gcom,gpir,gpo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1775174</th>\n",
       "      <td>ECOWEK0020250117el1h000fx</td>\n",
       "      <td>Economics; Researcher from Mersin Details Find...</td>\n",
       "      <td>2025 JAN 17 (VerticalNews) -- By a News Report...</td>\n",
       "      <td>Our news journalists obtained a quote from the...</td>\n",
       "      <td>Economics Week</td>\n",
       "      <td>1737072000000</td>\n",
       "      <td>en</td>\n",
       "      <td>422</td>\n",
       "      <td>NAMZ USA</td>\n",
       "      <td>,i43,icargo,iclt,icnp,itsp,</td>\n",
       "      <td>,c23,ccat,cscm,gcat,genv,gsust,</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                id  \\\n",
       "1775173  NBFSTA0020250129el1t0000k   \n",
       "1775174  ECOWEK0020250117el1h000fx   \n",
       "\n",
       "                                                     title  \\\n",
       "1775173  Jamaat-e-Islami Emir Hafiz Naeem ur Rehman ann...   \n",
       "1775174  Economics; Researcher from Mersin Details Find...   \n",
       "\n",
       "                                                   snippet  \\\n",
       "1775173  Jamaat-e-Islami Emir Hafiz Naeem ur Rehman has...   \n",
       "1775174  2025 JAN 17 (VerticalNews) -- By a News Report...   \n",
       "\n",
       "                                                      body     source_name  \\\n",
       "1775173  He hailed the return of millions of Gazans to ...   Frontier Star   \n",
       "1775174  Our news journalists obtained a quote from the...  Economics Week   \n",
       "\n",
       "        publication_date language word_count              region  \\\n",
       "1775173    1738108800000       en        542  ASIA PAKIS SASIAZ    \n",
       "1775174    1737072000000       en        422           NAMZ USA    \n",
       "\n",
       "                      industry_codes  \\\n",
       "1775173        ,i1,i16,ieutil,iutil,   \n",
       "1775174  ,i43,icargo,iclt,icnp,itsp,   \n",
       "\n",
       "                                             subject_codes  \n",
       "1775173  ,c314,ccat,cdom,gcat,gcivds,gcns,gcom,gpir,gpo...  \n",
       "1775174                    ,c23,ccat,cscm,gcat,genv,gsust,  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_trade.tail(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d2a61796-2e2d-4086-bfd9-c194e9478625",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21296, 12)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_trade.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "fe87073a-d466-41eb-930b-bfa885589a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_trade.to_pickle(r\"E:\\data\\FAyivodji\\data\\factiva_df_trade_news.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0182fed6-16ef-4579-98a0-dc2fe471d739",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad59c249-c237-43f4-91fa-4e62445ce0f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
